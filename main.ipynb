{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. 代码内容说明\n",
    "（启动训练及推理的方式、必要注释等）\n",
    "\n",
    "项目文件为**main.ipynb**\n",
    "直接运行所有代码块，完成训练与测试，如图：![](https://ai-studio-static-online.cdn.bcebos.com/e349720a7bb2432e92e4ce1ed54818d5859a89bdae6e4e2ba029fa2502c761c5)\n",
    "\n",
    "运行结束后即得到测试数据预测文件： **CVPR_2022_NAS_Track2_submit_A_frnn.json**\n",
    "\n",
    "若要直接读取已经训练好的模型，并在测试集进行预测，则直接运行**main_test.ipynb**\n",
    "\n",
    "文件的各代码块有必要的注释。\n",
    "\n",
    "对于各个任务，最优模型参数保存在**checkpoint/taskx_best.pdparams**文件，x为0,1，...，7。顺序为基线给定的顺序。**checkpoint_bkp**文件夹中有备份。\n",
    "\n",
    "# B. 模型构建思路及调优过程\n",
    "（可具体包括：思路框架图、思路步骤详述、模型应用+调优过程）\n",
    "\n",
    "主要是想利用模糊粗糙神经网络作为预测模型\n",
    "\n",
    "模型包括：\n",
    "1. 模糊化层\n",
    "2. 模糊规则层\n",
    "3. 粗糙层\n",
    "4. 输出层\n",
    "\n",
    "思路步骤详述：\n",
    "1. 模糊粗糙神经网络能够将输入模糊化，转化为模糊隶属度，之后得到模糊规则，粗糙层得到模糊粗糙隶属度，最后得到输出。\n",
    "2. 模糊粗糙神经网络可通过对网络架构输入进行学习，从而对网络精度进行预测。\n",
    "\n",
    "模型应用+调优过程：\n",
    "1. batch_size：大的batch_size性能不好，设为1后，发现预测性能明显好于基线\n",
    "2. learning_rate：一般，固定的学习率效果不好，采用了cosine退火\n",
    "3. 减少网络层：去除粗糙层、模糊层后，感觉效果有提升，只简单地比较了第一个task\n",
    "4. 增加隶属函数数目：FRNN的num_mf参数由2增到16\n",
    "5. 融合模糊化与全连接：效果没提升，没采用\n",
    "6. 保存最优模型：调试中发现，模型性能不稳定，不能保证最后得到的是最优的，因此，在优化过程中，每个epoch后，计算在验证集上的Kendalltau指标值，以保存最优模型参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# CVPR 2022 NAS workshop Track 2 Demo\n",
    "\n",
    "为了解决神经网络结构搜索的搜索效率和效果问题，百度联合悉尼科技大学和美国北卡罗来纳大学，以轻量级神经网络结构搜索技术为研究课题，提供技术、数据、算力等支持，全球招募挑战者共同切磋交流，打造最前沿的AI模型结构搜索技术。 百度在NAS领域原创性了提出了GP-NAS（CVPR），SA-NAS（IJCV）等AutoDL算法，使用研发的AutoDL算法先后7次CVPR，ECCV等国际比赛夺得世界第一，提交了200余项中国/美国专利申请。并孵化了[PaddleSlim](https://github.com/PaddlePaddle/PaddleSlim)模型压缩平台，PaddleSlim是百度基于飞桨PaddlePaddle打造的开源模型压缩工具库，囊括了深度学习模型压缩领域常用的量化、剪枝、蒸馏、模型结构搜索等方法，并且打造了CV和NLP领域的模型压缩方案。\n",
    "   \n",
    "本次比赛分为两个赛道，赛道一为[超网络赛道](https://aistudio.baidu.com/aistudio/competition/detail/149/0/introduction)，旨在解决OneshotNAS的一致性问题；赛道二为[模型性能预测赛道](https://aistudio.baidu.com/aistudio/competition/detail/150/0/introduction)，旨在不做任何训练的情况，准确的预测任意模型结构在特定评测集的性能。**获胜的队伍会被邀请在[CVPR 2022 NAS workshop](https://www.cvpr-nas.com/)上宣讲队伍的技术方案。 此外，各Track 前三名会被邀请提交论文（extended abstract论文可以不通过cmt系统提交，regular论文需要通过cmt系统提交) ，论文要求详见[CVPR NAS workshop论文提交页面](https://www.cvpr-nas.com/Paper_Submission)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 赛题介绍\n",
    "在不训练的情况下，准确的预测任意模型结构性能非常重要。基于此，我们不仅可以深度的分析怎样的模型结构会有很好的性能，怎样的模型性能会很差。同时还能够预测出满足任意硬件延时约束下的最优的模型结构。本赛事提供了部分（小样本）模型结构与模型精度之间对应关系的bench mark,参赛选手既可以通过黑盒的方式直接进行训练，也可以使用白盒的方式进行参数估计。最终预测泛化性能最好的模型将夺得冠军。相比去年的赛题，今年要求选手预测[VIMER-UFO](https://github.com/PaddlePaddle/VIMER/tree/main/UFO)中，任意单模型在多个任务上的性能。UFO这个技术设想的出发点是视觉的大一统，即一个模型能够覆盖所有主流的视觉任务。从垂类应用出发，选择了人脸、人体、车辆、商品四个任务作为视觉模型大一统的第一步。\n",
    "\n",
    "在本赛道中，超网络基于ViT-Base构建搜索空间，搜索空间维度有网络深度（depth）、自注意力头的数目（num_heads）、前向计算网络的膨胀系数（mlp_ratio)，其变化范围为depth \\in {10, 11, 12}，num_heads \\in {10, 11, 12}，mlp_ratio \\in {3.0, 3.5, 4.0}，搜索空间中有 9^10 + 9^11 + 9^12 个不同的子网络。\n",
    "子网的编码的长度为37，包括1位depth编码，以及12组的3位编码，分别指示为num_heads、mlp_ratio和embed_dim（在本次赛题中embed_dim为768，不作为搜索维度），实际depth小于12，则后尾填充0。对于depth编码，'j'，'k'和'l'分别表示10，11和12；对于num_heads编码，'1'，'2'和'3'表示12，11和10；对于mlp_ratio编码，'1'，'2'和'3'表示4.0, 3.5, 3.0，对于embed_dim编码，'1'表示768。以j111231321311311221231121111231000000为例，子网结构的depth为10，10层模型的num_heads的列表为[12, 11, 10, 10, 10, 11, 11, 12, 12, 11]，mlp_ratio的列表为[4.0, 3, 3.5, 4.0, 4.0, 3.5, 3, 3.5, 4.0, 3]，embed_dim的列表为[768, 768, 768, 768, 768, 768, 768, 768, 768, 768]。\n",
    "\n",
    "我们提供了训练数据，包括500个样本，其中输入为模型结构，标签为每个结构在8个任务上的相对排序rank，rank取值为0到499的整数；测试数据包括99500个样本，选手需要根据样本的结构信息训练多任务预测器（可以每个任务单独训练，也可以联合训练），并预测测试数据的99500个结构在8个任务上的排序，取值范围为0到99499。提交格式见『提交结果』\n",
    "\n",
    "比赛分A/B榜单，A/B榜单都基于选手提交的同一份提交文件，但是计算分数的节点的编号不同。比赛提交截止日期前仅A榜对选手可见，比赛结束后B榜会对选手公布，比赛最终排名按照选手成绩在B榜的排名。\n",
    "\n",
    "A榜队伍历史最高成绩（的json文件）和最后一次提交的json文件，会被用于计算Ｂ榜成绩，两个结果取最优。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:11:10.265134Z",
     "iopub.status.busy": "2022-05-21T02:11:10.264642Z",
     "iopub.status.idle": "2022-05-21T02:11:10.743589Z",
     "shell.execute_reply": "2022-05-21T02:11:10.742426Z",
     "shell.execute_reply.started": "2022-05-21T02:11:10.265095Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data134077\n",
      "CVPR_2022_NAS_Track1_test.json\tCVPR_2022_NAS_Track2_train.json\n",
      "CVPR_2022_NAS_Track2_test.json\tresnet48.pdparams\n"
     ]
    }
   ],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. \n",
    "# This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data\n",
    "!ls /home/aistudio/data/data134077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:27:20.238765Z",
     "iopub.status.busy": "2022-05-21T03:27:20.237692Z",
     "iopub.status.idle": "2022-05-21T03:27:20.247521Z",
     "shell.execute_reply": "2022-05-21T03:27:20.246679Z",
     "shell.execute_reply.started": "2022-05-21T03:27:20.238724Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cplfw_rank': 9, 'market1501_rank': 361, 'dukemtmc_rank': 426, 'msmt17_rank': 433, 'veri_rank': 327, 'vehicleid_rank': 480, 'veriwild_rank': 425, 'sop_rank': 367, 'arch': 'l231131331121121331111211121331321321'}\n",
      "train_num: 500\n"
     ]
    }
   ],
   "source": [
    "# 读取训练数据, 训练集包含500个模型结构，以及这些结构在cplfw，market1501，dukemtmc等8个任务上的性能排序\n",
    "import json\n",
    "with open('/home/aistudio/data/data134077/CVPR_2022_NAS_Track2_train.json', 'r') as f:\n",
    "    train_data = json.load(f)\n",
    "print(train_data['arch1'])\n",
    "print('train_num:',len(train_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理训练数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:11:32.453326Z",
     "iopub.status.busy": "2022-05-21T02:11:32.452210Z",
     "iopub.status.idle": "2022-05-21T02:11:32.546862Z",
     "shell.execute_reply": "2022-05-21T02:11:32.545823Z",
     "shell.execute_reply.started": "2022-05-21T02:11:32.453283Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 1, 1, 3, 1, 3, 3, 1, 1, 2, 1, 1, 2, 1, 3, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 3, 3, 1, 3, 2, 1, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "def convert_X(arch_str):\n",
    "    temp_arch = []\n",
    "    for elm in arch_str:\n",
    "        if elm == 'l':\n",
    "            temp_arch.append(1)\n",
    "        elif elm == 'j':\n",
    "            temp_arch.append(2)\n",
    "        elif elm == 'k':\n",
    "            temp_arch.append(3)\n",
    "        else: \n",
    "            temp_arch.append(int(elm))\n",
    "    return(temp_arch)\n",
    "train_list = [[],[],[],[],[],[],[],[]]\n",
    "arch_list_train = []\n",
    "name_list = ['cplfw_rank', 'market1501_rank', 'dukemtmc_rank', 'msmt17_rank', 'veri_rank', 'vehicleid_rank', 'veriwild_rank', 'sop_rank']\n",
    "for key in train_data.keys():\n",
    "    for idx, name in enumerate(name_list):\n",
    "        train_list[idx].append(train_data[key][name])\n",
    "    arch_list_train.append(convert_X(train_data[key]['arch']))\n",
    "print(arch_list_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练各任务预测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:27:24.500778Z",
     "iopub.status.busy": "2022-05-21T03:27:24.500300Z",
     "iopub.status.idle": "2022-05-21T03:27:27.019673Z",
     "shell.execute_reply": "2022-05-21T03:27:27.018701Z",
     "shell.execute_reply.started": "2022-05-21T03:27:24.500741Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddleslim in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim) (2.2.3)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim) (4.1.1.26)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim) (22.3.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim) (5.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim) (4.36.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim) (7.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim) (1.16.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim) (3.0.8)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim) (2019.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->paddleslim) (41.4.0)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 安装paddleslim\n",
    "!pip install paddleslim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:27:31.724973Z",
     "iopub.status.busy": "2022-05-21T03:27:31.724265Z",
     "iopub.status.idle": "2022-05-21T03:27:31.730496Z",
     "shell.execute_reply": "2022-05-21T03:27:31.729788Z",
     "shell.execute_reply.started": "2022-05-21T03:27:31.724933Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载python包\n",
    "import os\n",
    "import numpy as np\n",
    "from paddle.io import Dataset,DataLoader\n",
    "from paddle.vision import transforms as T\n",
    "from paddle.nn import functional as F\n",
    "import cv2\n",
    "import paddle\n",
    "import matplotlib.pyplot as plt\n",
    "import paddle.nn as nn\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from math import sqrt\n",
    "import time\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:27:34.586005Z",
     "iopub.status.busy": "2022-05-21T03:27:34.585487Z",
     "iopub.status.idle": "2022-05-21T03:27:34.594093Z",
     "shell.execute_reply": "2022-05-21T03:27:34.592848Z",
     "shell.execute_reply.started": "2022-05-21T03:27:34.585967Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 记录并计算平均值\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    Copied from: https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:27:37.898857Z",
     "iopub.status.busy": "2022-05-21T03:27:37.898163Z",
     "iopub.status.idle": "2022-05-21T03:27:37.909696Z",
     "shell.execute_reply": "2022-05-21T03:27:37.908765Z",
     "shell.execute_reply.started": "2022-05-21T03:27:37.898818Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模糊化层\n",
    "# 基于模糊集理论，对于每个输入，通过若干个隶属函数，转化为隶属度（0~1）\n",
    "class Fuzzify(nn.Layer):\n",
    "    def __init__(self,dim=2,flag_fix=False): # dim为每个输入对应的隶属函数数目，隶属函数选用高斯函数\n",
    "        super(Fuzzify, self).__init__()\n",
    "        self.dim = dim\n",
    "        if not flag_fix: # 隶属函数的参数是否是固定的\n",
    "            param_c = self.create_parameter([1,dim]) # 高斯函数的期望值\n",
    "            self.add_parameter(\"param_c\", param_c)\n",
    "            param_d = self.create_parameter([1,dim]) # 高斯函数的标准差\n",
    "            self.add_parameter(\"param_d\", param_d)\n",
    "            # init\n",
    "            self.param_c.set_value(np.random.rand(1,dim).astype(\"float32\")*3) # 初始化[0,3)，因为每个输入值取值为{0,1,2,3}\n",
    "            self.param_d.set_value(np.ones((1,dim)).astype(\"float32\")) # 初始化\n",
    "        else:\n",
    "            self.param_c = paddle.zeros([1, dim])\n",
    "            #self.param_d = paddle.ones([1, dim])\n",
    "            param_d = self.create_parameter([1,dim])\n",
    "            self.add_parameter(\"param_d\", param_d)\n",
    "            # init\n",
    "            for _ in range(dim):\n",
    "                self.param_c[0, _] = _\n",
    "            self.param_d.set_value(np.ones((1,dim)).astype(\"float32\"))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_out = []\n",
    "        for i in range(self.dim):\n",
    "            x_out.append(paddle.exp(-(x - self.param_c[0, i]) ** 2 * (2 * self.param_d[0, i] ** 2))) # 除以2\\delta^2 改为 乘以2\\delta^2\n",
    "        return paddle.concat(x_out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:27:40.967918Z",
     "iopub.status.busy": "2022-05-21T03:27:40.966462Z",
     "iopub.status.idle": "2022-05-21T03:27:40.979021Z",
     "shell.execute_reply": "2022-05-21T03:27:40.977932Z",
     "shell.execute_reply.started": "2022-05-21T03:27:40.967849Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FRNN(nn.Layer): # 模糊粗糙神经网络\n",
    "    def __init__(self,num_feat,num_mf=2,num_fr=7,num_rgh=3,num_classes=1):\n",
    "        super(FRNN, self).__init__()\n",
    "        '''\n",
    "        FRNN: fuzzification, fuzzy rule, rough, output\n",
    "        '''\n",
    "\n",
    "        '''\n",
    "        self.fuzz = Fuzzify(num_mf,flag_fix=False)\n",
    "        self.cnsq = nn.Sequential(\n",
    "            nn.Linear(num_feat,num_feat*num_mf),\n",
    "            nn.BatchNorm1D(num_feat*num_mf),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.out  = nn.Sequential(\n",
    "            nn.Linear(2*num_feat*num_mf,num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        '''\n",
    "        self.frnn = nn.Sequential(\n",
    "            Fuzzify(num_mf,flag_fix=False), # 模糊化层\n",
    "            #nn.Linear(num_feat*num_mf,num_fr), # 模糊规则层\n",
    "            #nn.BatchNorm1D(num_fr),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(num_fr,num_rgh), # 粗糙层\n",
    "            #nn.BatchNorm1D(num_rgh),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(num_rgh,num_classes), # 输出层\n",
    "            #nn.Linear(num_fr,num_classes), # 输出层\n",
    "            nn.Linear(num_feat*num_mf,num_classes), # 输出层\n",
    "            nn.Sigmoid() # 转到0~1\n",
    "        )\n",
    "        self.flag = False\n",
    "\n",
    "    def forward(self,x):\n",
    "        '''\n",
    "        x1 = self.fuzz(x)\n",
    "        x2 = self.cnsq(x)\n",
    "        x  = self.out(paddle.concat(x=[x1, x2], axis=1))\n",
    "        if not self.flag:\n",
    "            print(x.shape, x)\n",
    "            self.flag = True\n",
    "        return x\n",
    "        '''\n",
    "        return self.frnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:27:44.451451Z",
     "iopub.status.busy": "2022-05-21T03:27:44.450977Z",
     "iopub.status.idle": "2022-05-21T03:27:44.459406Z",
     "shell.execute_reply": "2022-05-21T03:27:44.458579Z",
     "shell.execute_reply.started": "2022-05-21T03:27:44.451413Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 评估网络模型\n",
    "def evaluation(model, params_file_path, valid_loader,flag_test=False):\n",
    "    if params_file_path is not None:\n",
    "        model_state_dict = paddle.load(params_file_path)\n",
    "        model.load_dict(model_state_dict)\n",
    "    model.eval()\n",
    "\n",
    "    all_pd = []\n",
    "    all_gt = []\n",
    "    for idx, data in enumerate(valid_loader()):\n",
    "        if flag_test:\n",
    "            arch_v = data\n",
    "        else:\n",
    "            arch_v, score_label = data\n",
    "\n",
    "        scores_predict = model(arch_v)\n",
    "\n",
    "        all_pd.append(scores_predict)\n",
    "        if not flag_test:\n",
    "            all_gt.append(score_label)\n",
    "\n",
    "    all_pd = paddle.concat(all_pd)\n",
    "    if flag_test: # 测试集没groundtruth\n",
    "        return all_pd.numpy()\n",
    "    else:\n",
    "        all_gt = paddle.concat(all_gt)\n",
    "        return scipy.stats.stats.kendalltau(all_pd.numpy(), all_gt.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:12:03.887989Z",
     "iopub.status.busy": "2022-05-21T02:12:03.887190Z",
     "iopub.status.idle": "2022-05-21T02:12:03.901302Z",
     "shell.execute_reply": "2022-05-21T02:12:03.900554Z",
     "shell.execute_reply.started": "2022-05-21T02:12:03.887943Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练预测网络模型\n",
    "def train(model,data_loader,eval_dataloader,task=0,Epoches=10,lr=0.05,eta_min=0.01):\n",
    "    paddle.set_device('cpu') # 不必使用GPU\n",
    "\n",
    "    # 启动训练\n",
    "    model.train()\n",
    "    # 获得数据读取器\n",
    "    data_loader = data_loader\n",
    "    nBatch = len(data_loader)\n",
    "    # 使用SGD优化器，学习率使用cosine退火\n",
    "    scheduler = paddle.optimizer.lr.CosineAnnealingDecay(learning_rate=lr, T_max=Epoches*nBatch, eta_min=eta_min, verbose=False)\n",
    "    opt = paddle.optimizer.SGD(learning_rate=scheduler, parameters=model.parameters())\n",
    "    # opt = paddle.optimizer.Adam(learning_rate=lr, parameters=model.parameters())\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "\n",
    "    cor_valid = 0\n",
    "\n",
    "    for epoch in range(0, Epoches):\n",
    "        with tqdm(total=nBatch//50+1,\n",
    "                  desc='Train Epoch #{}'.format(epoch + 1)) as t:\n",
    "            end = time.time()\n",
    "            for idx, data in enumerate(data_loader()):\n",
    "                data_time.update(time.time() - end)\n",
    "                new_lr = scheduler.last_lr\n",
    "                # 获得数据\n",
    "                arch_v, scores_label = data\n",
    "                # 计算出算法的前向计算结果\n",
    "                scores_predict = model(arch_v)\n",
    "                # 计算loss\n",
    "                loss = F.square_error_cost(scores_predict, scores_label)\n",
    "                avg_loss = paddle.mean(loss)\n",
    "\n",
    "                # 损失函数下降，并清除梯度\n",
    "                avg_loss.backward()\n",
    "                opt.step()\n",
    "                opt.clear_grad()\n",
    "                scheduler.step()\n",
    "\n",
    "                # measure accuracy and record loss\n",
    "                if np.isnan(avg_loss.item()):\n",
    "                    print(avg_loss.item())\n",
    "                losses.update(avg_loss.item(), arch_v.shape[0])\n",
    "\n",
    "                if idx % 50 == 0 or idx == nBatch - 1:\n",
    "                    t.set_postfix({\n",
    "                        'loss': losses.avg,\n",
    "                        'lr': new_lr,\n",
    "                        'data_time': data_time.avg,\n",
    "                    })\n",
    "                    t.update(1)\n",
    "                end = time.time()\n",
    "\n",
    "        # 每个epoch 保存一次模型\n",
    "        paddle.save(model.state_dict(), './checkpoint/task' + str(task) + '_epoch' + str(epoch) + '.pdparams')\n",
    "\n",
    "        tmp = evaluation(model, None, eval_dataloader)\n",
    "        print('Kendalltau:', tmp)\n",
    "        # 保存在验证集上表现最好的模型\n",
    "        if tmp.correlation > cor_valid:\n",
    "            paddle.save(model.state_dict(), './checkpoint/task' + str(task) + '_best' + '.pdparams')\n",
    "            cor_valid = tmp.correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T02:12:08.280676Z",
     "iopub.status.busy": "2022-05-21T02:12:08.280065Z",
     "iopub.status.idle": "2022-05-21T02:12:08.288748Z",
     "shell.execute_reply": "2022-05-21T02:12:08.287649Z",
     "shell.execute_reply.started": "2022-05-21T02:12:08.280633Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 构建数据集\n",
    "class ArchDataset(Dataset):\n",
    "    def __init__(self, data, label, transform=None):\n",
    "        super(ArchDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            return np.array(self.data[index]).astype(\"float32\"), np.array(self.label[index]).astype(\"float32\")\n",
    "        else:\n",
    "            return np.array(self.data[index]).astype(\"float32\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:27:54.290511Z",
     "iopub.status.busy": "2022-05-21T03:27:54.289889Z",
     "iopub.status.idle": "2022-05-21T03:27:57.840365Z",
     "shell.execute_reply": "2022-05-21T03:27:57.839067Z",
     "shell.execute_reply.started": "2022-05-21T03:27:54.290469Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[05-21 11:27:54 MainThread @utils.py:79]\u001b[0m \u001b[5m\u001b[33mWRN\u001b[0m paddlepaddle version: 2.2.2. The dynamic graph version of PARL is under development, not fully tested and supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  context = pyarrow.default_serialization_context()\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddleslim/common/analyze_helper.py:22: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://matplotlib_inline.backend_inline' by the following code:\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 534, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/base_events.py\", line 1771, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 471, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 460, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 367, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/kernelbase.py\", line 662, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/ipkernel.py\", line 360, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel/zmqshell.py\", line 532, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2962, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/events.py\", line 89, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib_inline/backend_inline.py\", line 217, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/IPython/core/pylabtools.py\", line 359, in activate_matplotlib\n",
      "    plt.switch_backend(backend)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('Agg')\n",
      "Train Epoch #1:  44%|████▍     | 4/9 [00:02<00:03,  1.52it/s, loss=0.104, lr=0.05, data_time=8.92e-5] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_159/2862757918.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#print([data[0], label[0]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrnn_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEpoches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEpoches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meta_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;31m# 读取最优模型参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mKendalltau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrnn_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./checkpoint/task'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_best'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.pdparams'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_159/4269973677.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, eval_dataloader, task, Epoches, lr, eta_min)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0march_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# 计算出算法的前向计算结果\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mscores_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# 计算loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare_error_cost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_159/2666828830.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         '''\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sub_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dygraph_call_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m_dygraph_call_func\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_159/3862215075.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mx_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 除以2\\delta^2 改为 乘以2\\delta^2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcontain_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_list_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m             \u001b[0;31m# 1. Call _getitem_impl_ when item contains tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m             \u001b[0;31m# Why not call a c++ function ? Because item can't be parsed when it contains tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/varbase_patch_methods.py\u001b[0m in \u001b[0;36mis_list_tuple\u001b[0;34m(index, contain_type)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mis_list_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontain_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0m_is_list_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from paddleslim.nas import GPNAS\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "\n",
    "gp_list = []\n",
    "frnn_list = []\n",
    "\n",
    "for i in range(len(train_list[:])):\n",
    "    # 每个任务有该任务专属的gpnas、FRNN预测器\n",
    "    gp_list.append(GPNAS(2,2))\n",
    "    frnn_list.append(FRNN(num_feat=37,num_mf=16,num_fr=8,num_rgh=4,num_classes=1))\n",
    "\n",
    "train_num = 400\n",
    "batch_size = 1\n",
    "Epoches = 100\n",
    "\n",
    "\n",
    "for i in range(len(train_list[:])):\n",
    "    # 划分训练及测试集\n",
    "    X_all_k, Y_all_k  = np.array(arch_list_train), np.array(train_list[i])\n",
    "    X_train_k, Y_train_k, X_test_k, Y_test_k = X_all_k[0:train_num:1], Y_all_k[0:train_num:1], X_all_k[train_num::1], Y_all_k[train_num::1]\n",
    "    # 获取数据读取器\n",
    "    Y_train_k = Y_train_k / max(Y_train_k)\n",
    "    train_dataset = ArchDataset(X_train_k, Y_train_k)\n",
    "    eval_dataset = ArchDataset(X_test_k, Y_test_k)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    eval_dataloader = DataLoader(eval_dataset, batch_size=100, shuffle=True, drop_last=False)\n",
    "    # 观察数据读取是否正常\n",
    "    data, label = next(train_dataloader())\n",
    "    #print([data[0], label[0]])\n",
    "    #\n",
    "    train(frnn_list[i], train_dataloader,eval_dataloader,i,Epoches=Epoches,lr=0.05,eta_min=0.002)\n",
    "    # 读取最优模型参数\n",
    "    Kendalltau = evaluation(frnn_list[i], './checkpoint/task' + str(i) + '_best' + '.pdparams', eval_dataloader)\n",
    "    print('Kendalltau:', Kendalltau)\n",
    "    # 初始该任务的gpnas预测器参数\n",
    "    gp_list[i].get_initial_mean(X_train_k[0::2],Y_train_k[0::2])\n",
    "    init_cov = gp_list[i].get_initial_cov(X_train_k)\n",
    "    # 更新（训练）gpnas预测器超参数\n",
    "    gp_list[i].get_posterior_mean(X_train_k[1::2],Y_train_k[1::2])  \n",
    "   \n",
    "    # 基于测试评估预测误差   \n",
    "    error_list_gp = np.array(Y_test_k.reshape(len(Y_test_k),1)-gp_list[i].get_predict(X_test_k))\n",
    "    error_list_gp_j = np.array(Y_test_k.reshape(len(Y_test_k),1)-gp_list[i].get_predict_jiont(X_test_k, X_train_k[::1], Y_train_k[::1]))\n",
    "    print('AVE mean gp :',np.mean(abs(np.divide(error_list_gp,Y_test_k.reshape(len(Y_test_k),1) ))))\n",
    "    print('AVE mean gp jonit :',np.mean(abs(np.divide(error_list_gp_j,Y_test_k.reshape(len(Y_test_k),1) ))))\n",
    "    y_predict = gp_list[i].get_predict_jiont(X_test_k, X_train_k[::1], Y_train_k[::1])\n",
    "\n",
    "    #基于测试集评估预测的Kendalltau\n",
    "    print('Kendalltau:',scipy.stats.stats.kendalltau( y_predict,Y_test_k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 查看测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('/home/aistudio/data/data134077/CVPR_2022_NAS_Track2_test.json', 'r') as f:\n",
    "    test_data = json.load(f)\n",
    "test_data['arch99997']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理测试集数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_arch_list = []\n",
    "for key in test_data.keys():\n",
    "    test_arch =  convert_X(test_data[key]['arch'])\n",
    "    test_arch_list.append(test_arch)\n",
    "print(test_arch_list[99499])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测各任务上的测试集的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "rank_all = []\n",
    "pd_all_frnn = [] # 预测值\n",
    "rank_all_frnn = [] # 预测排序\n",
    "for task in range(len(name_list)):\n",
    "    print('Predict the rank of:', name_list[task])\n",
    "    \n",
    "    X_test_k = np.array(test_arch_list)\n",
    "    test_dataset = ArchDataset(X_test_k, None)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    # slow mode\n",
    "    # rank_all.append(gp_list[task].get_predict_jiont(np.array(test_arch_list), np.array(arch_list_train), np.array(train_list[task])))\n",
    "    # fast mode\n",
    "    rank_all.append(gp_list[task].get_predict(np.array(test_arch_list)))\n",
    "    # 测试最优模型参数\n",
    "    all_pd = evaluation(frnn_list[task], './checkpoint/task' + str(task) + '_best' + '.pdparams',\n",
    "                        test_dataloader, flag_test=True)\n",
    "    pd_all_frnn.append(all_pd)\n",
    "    tmp = np.argsort(all_pd.reshape(-1))\n",
    "    tmp2 = np.argsort(tmp) # 获得排名\n",
    "    rank_all_frnn.append(tmp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-31T10:11:06.070408Z",
     "iopub.status.idle": "2022-03-31T10:11:06.070662Z",
     "shell.execute_reply": "2022-03-31T10:11:06.070551Z",
     "shell.execute_reply.started": "2022-03-31T10:11:06.070539Z"
    }
   },
   "source": [
    " # 生成提交结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx,key in enumerate(test_data.keys()):\n",
    "    test_data[key]['cplfw_rank'] = int(rank_all[0][idx][0])\n",
    "    test_data[key]['market1501_rank'] = int(rank_all[1][idx][0])\n",
    "    test_data[key]['dukemtmc_rank'] = int(rank_all[2][idx][0])\n",
    "    test_data[key]['msmt17_rank'] = int(rank_all[3][idx][0])\n",
    "    test_data[key]['veri_rank'] = int(rank_all[4][idx][0])\n",
    "    test_data[key]['vehicleid_rank'] = int(rank_all[5][idx][0])\n",
    "    test_data[key]['veriwild_rank'] = int(rank_all[6][idx][0])\n",
    "    test_data[key]['sop_rank'] = int(rank_all[7][idx][0])\n",
    "print('Ready to save results!')\n",
    "with open('./CVPR_2022_NAS_Track2_submit_A.json', 'w') as f: # 得到baseline\n",
    "    json.dump(test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx,key in enumerate(test_data.keys()):\n",
    "    test_data[key]['cplfw_rank'] = int(rank_all_frnn[0][idx])\n",
    "    test_data[key]['market1501_rank'] = int(rank_all_frnn[1][idx])\n",
    "    test_data[key]['dukemtmc_rank'] = int(rank_all_frnn[2][idx])\n",
    "    test_data[key]['msmt17_rank'] = int(rank_all_frnn[3][idx])\n",
    "    test_data[key]['veri_rank'] = int(rank_all_frnn[4][idx])\n",
    "    test_data[key]['vehicleid_rank'] = int(rank_all_frnn[5][idx])\n",
    "    test_data[key]['veriwild_rank'] = int(rank_all_frnn[6][idx])\n",
    "    test_data[key]['sop_rank'] = int(rank_all_frnn[7][idx])\n",
    "print('Ready to save results!')\n",
    "with open('./CVPR_2022_NAS_Track2_submit_A_frnn.json', 'w') as f: # 得到提出方案的预测值\n",
    "    json.dump(test_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-21T03:29:31.636263Z",
     "iopub.status.busy": "2022-05-21T03:29:31.635631Z",
     "iopub.status.idle": "2022-05-21T03:29:36.234839Z",
     "shell.execute_reply": "2022-05-21T03:29:36.233849Z",
     "shell.execute_reply.started": "2022-05-21T03:29:31.636202Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pipreqs\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1a/cd/74bbb901d65c375e2e8ab5601a4071d4ef38c745f6d4da74add61f964b9a/pipreqs-0.4.11-py2.py3-none-any.whl (32 kB)\n",
      "Collecting yarg\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8b/90/89a2ff242ccab6a24fbab18dbbabc67c51a6f0ed01f9a0f41689dc177419/yarg-0.1.9-py2.py3-none-any.whl (19 kB)\n",
      "Collecting docopt\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from yarg->pipreqs) (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->yarg->pipreqs) (1.25.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->yarg->pipreqs) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->yarg->pipreqs) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->yarg->pipreqs) (2.8)\n",
      "Building wheels for collected packages: docopt\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13704 sha256=74c5da908539b8d18f92bf712b07930b23a9e2a13ddd3107a368392aef3d65eb\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/17/d9/6e/6b3eb21ad36a388d8d7eb1c1c61e34c627876458e6fc37790d\n",
      "Successfully built docopt\n",
      "Installing collected packages: docopt, yarg, pipreqs\n",
      "Successfully installed docopt-0.6.2 pipreqs-0.4.11 yarg-0.1.9\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/envs/python35-paddle120-env/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: Successfully saved requirements file in /home/aistudio/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!pip install pipreqs\r\n",
    "!pipreqs --use-local --encoding=utf8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
